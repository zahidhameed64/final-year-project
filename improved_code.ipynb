{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Statistics Analysis & Prediction\n",
    "\n",
    "This notebook performs exploratory data analysis (EDA), feature engineering, and machine learning modeling on Global YouTube Statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# --- Machine Learning ---\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# --- Settings ---\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"viridis\")\n",
    "plt.style.use('dark_background') # Maintaining the visual style if preferred, or standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_data(filepath):\n",
    "    \"\"\"\n",
    "    Loads the dataset, handles encoding, and performs initial cleaning.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"UTF-8 encoding failed, using latin-1.\")\n",
    "        df = pd.read_csv(filepath, encoding='latin-1')\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"File named '{filepath}' not found. Please ensure it is in the same directory.\")\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    columns_to_drop = [\n",
    "        'rank', 'Abbreviation', 'country_rank', 'created_month',\n",
    "        'created_date', 'Gross tertiary education enrollment (%)',\n",
    "        'Unemployment rate', 'Urban_population', 'Latitude', 'Longitude'\n",
    "    ]\n",
    "    # Only drop if they exist\n",
    "    df = df.drop(columns=[c for c in columns_to_drop if c in df.columns], errors='ignore')\n",
    "\n",
    "    # Handle Missing Values\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = df[col].fillna(\"Unknown\")\n",
    "    \n",
    "    for col in df.select_dtypes(include=['int64', 'float']).columns:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    # Correct Data Types\n",
    "    for col in ['video views', 'uploads', 'subscribers']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype('int64')\n",
    "\n",
    "    # Filter illogical data\n",
    "    if 'video views' in df.columns and 'created_year' in df.columns:\n",
    "        df = df[(df['video views'] > 0) & (df['created_year'] >= 2005)]\n",
    "\n",
    "    # Sort and reset index\n",
    "    if 'subscribers' in df.columns:\n",
    "        df = df.sort_values(by='subscribers', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Data cleaning complete. Shape: {df.shape}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"\n",
    "    Creates new features for analysis and modeling.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    current_year = datetime.datetime.now().year\n",
    "    \n",
    "    if 'created_year' in df.columns:\n",
    "        df['channel_age'] = current_year - df['created_year']\n",
    "        df['channel_age'] = df['channel_age'].apply(lambda x: x if x >= 0 else 0)\n",
    "\n",
    "    if 'video views' in df.columns and 'subscribers' in df.columns:\n",
    "        df['views_per_subscriber'] = df['video views'] / df['subscribers']\n",
    "        df['views_per_subscriber'] = df['views_per_subscriber'].fillna(0)\n",
    "\n",
    "    if 'uploads' in df.columns and 'channel_age' in df.columns:\n",
    "        df['uploads_per_day'] = df['uploads'] / (df['channel_age'] * 365.25)\n",
    "        df['uploads_per_day'] = df['uploads_per_day'].fillna(0).replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    if 'subscribers' in df.columns:\n",
    "        def get_tier(subs):\n",
    "            if subs >= 1e8: return 'Mega'\n",
    "            elif subs >= 1e7: return 'Macro'\n",
    "            elif subs >= 1e6: return 'Mid'\n",
    "            elif subs >= 1e5: return 'Micro'\n",
    "            else: return 'Nano'\n",
    "        df['subscriber_tier'] = df['subscribers'].apply(get_tier)\n",
    "    \n",
    "    print(\"Feature engineering complete.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(df, columns):\n",
    "    \"\"\"\n",
    "    Removes outliers using the IQR method for specified columns.\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    for col in columns:\n",
    "        if col in df_clean.columns:\n",
    "            Q1 = df_clean[col].quantile(0.25)\n",
    "            Q3 = df_clean[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower = Q1 - 1.5 * IQR\n",
    "            upper = Q3 + 1.5 * IQR\n",
    "            df_clean = df_clean[(df_clean[col] >= lower) & (df_clean[col] <= upper)]\n",
    "    \n",
    "    print(f\"Rows after outlier removal: {df_clean.shape[0]} (Original: {df.shape[0]})\")\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_preprocessor(categorical_cols, numerical_cols):\n",
    "    \"\"\"\n",
    "    Creates a ColumnTransformer for preprocessing.\n",
    "    \"\"\"\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_cols),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_eda(df):\n",
    "    \"\"\"\n",
    "    Generates validation plots.\n",
    "    \"\"\"\n",
    "    # 1. Distribution of Channel Types\n",
    "    if 'channel_type' in df.columns:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.countplot(y='channel_type', data=df, order=df['channel_type'].value_counts().index, palette='viridis')\n",
    "        plt.title('Distribution of Channel Types')\n",
    "        plt.show()\n",
    "\n",
    "    # 2. Correlation Matrix\n",
    "    num_df = df.select_dtypes(include=[np.number])\n",
    "    if not num_df.empty:\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(num_df.corr(), annot=True, fmt='.2f', cmap='coolwarm')\n",
    "        plt.title('Correlation Heatmap')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Execution ---\n",
    "\n",
    "# 1. Load Data\n",
    "filename = 'Global YouTube Statistics.csv'\n",
    "try:\n",
    "    df = load_and_clean_data(filename)\n",
    "    \n",
    "    # 2. EDA\n",
    "    perform_eda(df)\n",
    "\n",
    "    # 3. Feature Engineering\n",
    "    df = engineer_features(df)\n",
    "\n",
    "    # 4. Outlier Removal\n",
    "    numerical_cols_for_outliers = [\n",
    "        'subscribers', 'video views', 'uploads', 'channel_age',\n",
    "        'views_per_subscriber', 'uploads_per_day'\n",
    "    ]\n",
    "    df_ml = remove_outliers_iqr(df, numerical_cols_for_outliers)\n",
    "\n",
    "    # 5. Prepare ML Data\n",
    "    target = 'video views'\n",
    "    if target in df_ml.columns:\n",
    "        X = df_ml.drop(['Title', 'Youtuber', target], axis=1, errors='ignore')\n",
    "        y = df_ml[target]\n",
    "\n",
    "        # Identify columns again after drops\n",
    "        categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "        numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        preprocessor = build_preprocessor(categorical_features, numerical_features)\n",
    "\n",
    "        # 6. Train Linear Regression\n",
    "        print(\"Training Linear Regression...\")\n",
    "        lr_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                      ('regressor', LinearRegression())])\n",
    "        lr_pipeline.fit(X_train, y_train)\n",
    "        y_pred_lr = lr_pipeline.predict(X_test)\n",
    "        print(f\"Linear Regression R2: {r2_score(y_test, y_pred_lr):.4f}\")\n",
    "\n",
    "        # 7. Train Random Forest\n",
    "        print(\"Training Random Forest...\")\n",
    "        rf_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                      ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))])\n",
    "        rf_pipeline.fit(X_train, y_train)\n",
    "        y_pred_rf = rf_pipeline.predict(X_test)\n",
    "        print(f\"Random Forest R2: {r2_score(y_test, y_pred_rf):.4f}\")\n",
    "    else:\n",
    "        print(f\"Target column '{target}' not found.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during execution: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
